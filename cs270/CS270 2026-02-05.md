2026 02 05  
CS 270  
Quin Snell  
Regularization  

---

Today is going to be more mathy than normal, Dr. Snell warned.

# Simple vs. Multiple Linear Regression

Simple linear regression: Just a line.

$\hat y = w_1x + w_0$

- $w_1$ = weight
- $w_0$ = bias

Multiple linear regression: More features.

$\hat y = w_0 + w_1x_1 + \dots + w_px_p$

- $w_k$ is the weight associated to feature $x_k$.

For simple linear regression, it's ez to calculate the weights. For multiple linear regression, it takes a lot of matrix math to solve for the weights, and that's computationally expensive. So instead we use algorithms that iteratively "search" for the weights.

# Non-linear regression

Even in 2D, a line doesn't always fit your data super well. A curve oft fits better. But you need more terms in your equation for $\hat y$ to make a curve (**NON-LINEAR**). And in ML, what does each term represent? A feature. So now we're making up features (that ig you didn't initially record or smth? idrk) to make a better regression model. This is called **FEATURE ENGINEERING**.

e.g. adding $x^2$ or $x^3$ terms.

## Minimizing error

So you're regression equation will look smth like this now:

$$\hat y = w_0 + w_1x_1 + w_2x^2_2 + \dots + w_3x^3_3 + \dots + w_px^p_p$$

The question is, what order of polynomial should you make your curve?

- MORE TERMS/TOO HIGH EXPs results in OVERFITTING.
  - When OVERFITTED, a non-linear regression model will have HIGH TRAINING SCORES but LOW VALIDATION/TEST SCORES. 
    - For a non-linear regression model, this looks like a curve that crosses through your training data beautifully...but the curve goes crazy in btwn those data points.
- TOO FEW TERMS/TOO LOW EXPs results in UNDERFITTING.

So what you'll do is this: Start w/ very few terms, then keep training models w/ more and more terms&mdash;until your model starts to get weaker. Then, you just use the best model you've seen thus far. (BUT DO THIS WITH YOUR *VALIDATION* SET, *NOT* YOUR TEST SET.)

*(Hey wait...this is what Lotus was talking ab where if you keep training your model, it starts to get worse. That's so bing chilling interesting.)*

One way to think of this process is **adding a "penalty" to complexity**. This is called "regularization", which is what this lecture is about.

# REGULARIZATION

- **REGULARIZATION:** Reduce GENERALIZATION ERROR&mdash;but not necessarily training err.
  - (Sometimes, the training err might even increase.)

Some history: Occam's Razor states that the simplest explanation is oft the correct explanation (c. 1200s). Then in the 40s some guy introduced the term regularization or smth. Idrk but I don't think it's important.

- Regularization is accomplished by **changing the loss function**. 
  - In addition to SSE (error), we'll **add a penalty for complexity**.
  - ^ This discourages weights from going crazy.

$$\text{Total loss} = \text{Error} + \lambda \times \text{Penalty}$$

- $\text{Penalty}$ is the penalty for complexity.
- $\lambda$ is a multiplier to that penalty, to control how much weight that has in our loss function.
  - NOTE: sklearn uses $\alpha$ instead of $\lambda$.
- ($\text{Error}$ is usually SSE)

In the slides, that typically looks like this:

$$L(\vec w) = E(\vec w) + \text{Penalty}(\vec w)$$

- Where $\vec w \in \mathbb R^n$ is a...weight? So like what does $w_1, w_2, \dots, w_n$ represent...idk.
- $L$ is loss.
- $E$ is error (usually SSE).

The different regression types will differ on what $\text{Penalty}(\vec w)$ is.


## Methods of regularization

With L2 and LASSO regularization, we modify the loss functions w/ penalties so that some weights get reduced&mdash;ideally to zero, eliminating terms. Conceptually speaking, this means you're eliminating unimportant features.

### L2: Ridge Regularization

L2's penalty term looks like this:

$$\lambda \sum w^2_i$$

The gradient descent is given by:

$$-\nabla L(\vec w) = -\nabla E(\vec w) - 2\lambda w_i$$

(I have no clue what $\nabla$ is)

### L1: LASSO (Least Absolute Shrinkage & Selection Operator)

(So actually, Tibshirani (1996) came up with the term "lasso" first, and then found an acronym to fit it. Lol.)

Penalty term:

$$\lambda \sum | w_i |$$

Gradient descent is given by:

$$-\nabla L(\vec w) = -\nabla E(\vec w) - \lambda$$

### Ridge (L2) vs. LASSO (L1)

- Ridge squares, LASSO absvals. Why does that matter?
  - Consider values less than one. When squared, they become smaller. So **ridge regularization can't actually reduce weights completely to zero, while LASSO can.**
    <!-- - ~~So, Dr. Snell says, LASSO regularization "drops to zero" faster...not rly sure wtf he's talking ab tbh.~~ -->
    <!-- - ^ OH he's talking about reducing weights to zero, eliminating terms. So conceptually, that's removing poopy features. -->
  - (Sparse rep and feature reduction)
  - Good if you have features that should be ignored.
- L1 more robust to large weights (outliers), while L2 acts more dramatically w/ large weights. (wtf does this mean??)
- L1 leads to simpler models, but L2 is oft more accurate w/ problems that demand a bit more complexity.

### Elastic Net Regularization

Elastic Net blends L1 & L2:

$$\lambda_1 \sum |w_i| + \lambda_2 \sum w_i^2$$

- $\lambda_1$ is a multiplier for L1.
- $\lambda_2$ is a multiplier for L2.
- (NOTE: Sklearn uses $\alpha$ and $\lambda$.)

<!-- $$L(\vec w) = E(\vec w) + \lambda_1 \sum |w_i| + \lambda_2 \sum w_i^2$$ -->

## Better, not perfect

Remember that you're never ever going to get a perfect model. Regularization improves generalization, but it won't make a perfect model.

The "Free Lunch Theorem" of Machine Learning: There does not exist a model that is perfect for any situation. (This is has a proof...so that's neat.)

## Choosing regularization method

- Elastic net can give you the best of both worlds...but it introduces two hyperparams.
- Some folks will use L1 as a diagnostic and L2 in their final model: So they'll train L1 to see what features it eliminates, then train L2 while excluding those features.

But let's dive deeper into each regularization method's usages & strengths.

### Ridge (L2) 

- Think of it as a "dimmer switch". It will dim the effects of features, but never shut them completely off.
- If you have two features that are highly correlated, rather than eliminate one, it will just kinda dim them down.
  - That makes it hard to tell which is important, but it allows you to make the decision which one to keep.
- BEST USE CASE: You have multiple features that each contribute a wee bit to the outcome, OR when you have highly correlated features.
  - With highly correlated features, L2 effectively distributes weight evenly among them. 

### LASSO (L1)

- Think of it as a "toggle switch". It can completely eliminate features.
- ^ So LASSO is good for FEATURE SELECTION.
- BEST USE CASE: You have a ton of features, but you don't know if they all rly matter.

### Elastic Net

- BEST USE CASE: You have several features that are highly correlated.
  - Lasso might randomly pick one and ignore the rest; Elastic Net will likely keep the whole group (thanks to Ridge).
    - Whether or not it keeps the whole group depends on whether you put more weight on the L1 or the L2 penalty.

## Regularization in the real world

Regularization is very important in deep learning and neural networks, Dr. Snell said.


## How to remember L1 vs. L2

- LASSO is L**1**: **LINEAR**.
- RIDGE is L**2**: Weights are **SQUARED**.